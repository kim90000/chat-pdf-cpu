{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9N2KAfqxCPwW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p5OMQHC9CQWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/DS4SD/docling/blob/main/docs/examples/rag_langchain.ipynb"
      ],
      "metadata": {
        "id": "AtAQ8JZSCWoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq docling docling-core python-dotenv langchain-text-splitters langchain-huggingface langchain-milvus"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f12afe32-e46d-4d22-8322-af653a2980e2",
        "id": "D753cBoo4T93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/226.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.4/226.4 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cfdcd7d-4e43-4db4-b14a-f3c94e555aa0",
        "id": "B1Ldt0UM4T95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Iterator\n",
        "\n",
        "from langchain_core.document_loaders import BaseLoader\n",
        "from langchain_core.documents import Document as LCDocument\n",
        "\n",
        "from docling.document_converter import DocumentConverter\n",
        "\n",
        "class DoclingPDFLoader(BaseLoader):\n",
        "\n",
        "    def __init__(self, file_path: str | list[str]) -> None:\n",
        "        self._file_paths = file_path if isinstance(file_path, list) else [file_path]\n",
        "        self._converter = DocumentConverter()\n",
        "\n",
        "    def lazy_load(self) -> Iterator[LCDocument]:\n",
        "        for source in self._file_paths:\n",
        "            dl_doc = self._converter.convert(source).document\n",
        "            text = dl_doc.export_to_markdown()\n",
        "            yield LCDocument(page_content=text)"
      ],
      "metadata": {
        "id": "55q2lg5H4T95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "FILE_PATH = \"/content/Coal2022.pdf\""
      ],
      "metadata": {
        "id": "juRTxYJ44T96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "loader = DoclingPDFLoader(file_path=FILE_PATH)\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        ")"
      ],
      "metadata": {
        "id": "ZzyxxA-e4T96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = loader.load()\n",
        "splits = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8f0d86a-bf60-4d9f-fa0f-3c5039aac3e5",
        "id": "D64KkbkE4T97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "HF_EMBED_MODEL_ID = \"BAAI/bge-small-en-v1.5\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=HF_EMBED_MODEL_ID)"
      ],
      "metadata": {
        "id": "hLwmLRSm4T98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tempfile import TemporaryDirectory\n",
        "\n",
        "from langchain_milvus import Milvus\n",
        "\n",
        "MILVUS_URI = os.environ.get(\n",
        "    \"MILVUS_URI\", f\"{(tmp_dir := TemporaryDirectory()).name}/milvus_demo.db\"\n",
        ")\n",
        "\n",
        "vectorstore = Milvus.from_documents(\n",
        "    splits,\n",
        "    embeddings,\n",
        "    connection_args={\"uri\": MILVUS_URI},\n",
        "    drop_old=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5265df8-97cc-4aa1-de62-9d4e8997a714",
        "id": "vHw13ar_4T98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-12-31 23:06:07,759 [ERROR][handler]: RPC error: [create_index], <MilvusException: (code=65535, message=invalid index type: HNSW, local mode only support FLAT IVF_FLAT AUTOINDEX: )>, <Time:{'RPC start': '2024-12-31 23:06:07.757695', 'RPC error': '2024-12-31 23:06:07.759854'}> (decorators.py:140)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "import torch\n",
        "HF_API_KEY = os.environ.get(\"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
        "HF_LLM_MODEL_ID = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "\n",
        "\n",
        "\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=HF_LLM_MODEL_ID,\n",
        "    device=\"auto\",\n",
        "    # Change torch_dtype to a string instead of a torch.dtype object\n",
        "    torch_dtype=\"float32\",\n",
        "    huggingfacehub_api_token=HF_API_KEY,\n",
        "    do_sample=True,\n",
        "    max_new_tokens=50,\n",
        ")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4de969e6-9962-42ee-c662-c4fed409a6bd",
        "id": "xOWL5XeF4T99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_huggingface.llms.huggingface_endpoint:WARNING! device is not default parameter.\n",
            "                    device was transferred to model_kwargs.\n",
            "                    Please make sure that device is what you intended.\n",
            "WARNING:langchain_huggingface.llms.huggingface_endpoint:WARNING! torch_dtype is not default parameter.\n",
            "                    torch_dtype was transferred to model_kwargs.\n",
            "                    Please make sure that torch_dtype is what you intended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Iterable\n",
        "\n",
        "from langchain_core.documents import Document as LCDocument\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "\n",
        "def format_docs(docs: Iterable[LCDocument]):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"Context information is below.\\n---------------------\\n{context}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {question}\\nAnswer:\\n\"\n",
        ")\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "cCvla5yL4T9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain.invoke(\"What is the main topic of the book?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "9408d96f-8898-45ef-cd0f-2610888c3bbb",
        "id": "7FNVsq_Z4T9-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There is no book mentioned in the provided context information. The text appears to be a part of an article or a report discussing the international coal trade and the impact of Russia sanctions. Therefore, I cannot provide an answer to the query.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain.invoke(\"How many pages in the book /content/Coal2022.pdf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "PYFdWcnv_arY",
        "outputId": "15d78749-391d-49cd-8165-afbede2ff7fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Unfortunately, the query cannot be answered with the provided information. The query asks for a page count of a PDF file, but the context information only provides an overview of the content of the Coal2022 report, including its title, publication history, and'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain.invoke(\"Can you tell me what you know about the book? /content/Coal2022.pdf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "iCyHpl5f_j3n",
        "outputId": "8125e157-f34c-43bd-f699-43e24ee04c7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The text appears to be a report or a document related to the coal industry. The title of the report is \"Coal 2022\", and it seems to cover a range of topics such as coal demand, supply, trade, costs, and prices'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain.invoke(\"Can you show me the information in the book about the demand for coal? /content/Coal2022.pdf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "wsy8-_7DAVyY",
        "outputId": "30673ce4-4073-49fe-8c9f-f2c1bc961a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The text does not provide the information in the book \"Coal2022.pdf\". However, according to the context information, the book \"Coal2022\" provides a thorough analysis of recent trends in coal demand, supply, trade, costs and prices against'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain.invoke(\"Can you give advice on coal trading is it profitable or not from the book /content/Coal2022.pdf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "VaA6aLvrAuLg",
        "outputId": "4ad962b9-2073-4e47-9db2-c891806ee212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Based on the provided context information, it appears that coal trading is not a highly profitable venture, especially outside of China and India. The high prices of coal since October 2021 have not led to a significant uptick in investment in coal mining projects'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}